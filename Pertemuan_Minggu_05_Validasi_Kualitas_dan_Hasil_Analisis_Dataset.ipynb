{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtXTHDEZBwZH"
      },
      "source": [
        "# Pertemuan 5 - Validasi Kualitas dan Hasil Analisis Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SBHQ9hZBwZI"
      },
      "source": [
        "## 1. Data Cleaning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CbZ1hcEBwZJ"
      },
      "source": [
        "### A. Mengatasi Missing Values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "j-4QcX0pBwZK",
        "outputId": "a4d6e18b-c30c-4225-8266-e464126779d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Awal:\n",
            "      Name   Age         City\n",
            "0    Alice  25.0     New York\n",
            "1      Bob  30.0  Los Angeles\n",
            "2  Charlie  35.0      Chicago\n",
            "3    Alice  25.0     New York\n",
            "4      Eve   NaN        Miami\n",
            "5      NaN  50.0  Los Angeles\n",
            "\n",
            "Data Setelah Cleaning:\n",
            "      Name   Age         City\n",
            "0    Alice  25.0     New York\n",
            "1      Bob  30.0  Los Angeles\n",
            "2  Charlie  35.0      Chicago\n",
            "4      Eve  32.5        Miami\n",
            "\n",
            "‚úÖ Data telah disimpan sebagai 'data.csv'\n"
          ]
        }
      ],
      "source": [
        "# data_cleaning.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Membuat dataframe contoh\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'Alice', 'Eve', np.nan],\n",
        "    'Age': [25, 30, 35, 25, np.nan, 50],\n",
        "    'City': ['New York', 'Los Angeles', 'Chicago', 'New York', 'Miami', 'Los Angeles']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Menampilkan data awal\n",
        "print(\"Data Awal:\")\n",
        "print(df)\n",
        "\n",
        "# Menghapus duplikat\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# Menangani missing values dengan mengisi nilai median untuk kolom numerik\n",
        "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
        "\n",
        "# Menghapus baris yang mengandung missing values di kolom 'Name'\n",
        "df = df.dropna(subset=['Name'])\n",
        "\n",
        "# Menampilkan data setelah cleaning\n",
        "print(\"\\nData Setelah Cleaning:\")\n",
        "print(df)\n",
        "\n",
        "# **Simpan file CSV dengan benar**\n",
        "df.to_csv('data.csv', index=False)\n",
        "print(\"\\n‚úÖ Data telah disimpan sebagai 'data.csv'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JjRfmd9BwZK",
        "outputId": "fb1d3d5f-328e-42f9-9d81-13c019d4f126"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Jumlah Missing Values dalam 'data.csv':\n",
            "Name    0\n",
            "Age     0\n",
            "City    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# check_missing_values.py\n",
        "import pandas as pd\n",
        "\n",
        "# Coba membaca file CSV yang telah dibuat\n",
        "try:\n",
        "    df = pd.read_csv('data.csv')\n",
        "    print(\"\\nüìä Jumlah Missing Values dalam 'data.csv':\")\n",
        "    print(df.isnull().sum())\n",
        "except FileNotFoundError:\n",
        "    print(\"\\n‚ùå File 'data.csv' tidak ditemukan! Jalankan 'data_cleaning.py' terlebih dahulu.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjlMaKwDBwZK",
        "outputId": "2ffd7c3c-14a6-4ea6-c374-0b7af2cf4fe3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Minyau$\\AppData\\Local\\Temp\\ipykernel_896\\903522314.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Age'].fillna(df['Age'].median(), inplace=True)  # Median\n",
            "C:\\Users\\Minyau$\\AppData\\Local\\Temp\\ipykernel_896\\903522314.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Age'].fillna(df['Age'].mode()[0], inplace=True)  # Mode\n"
          ]
        }
      ],
      "source": [
        "# Mengisi Missing Values\n",
        "df['Age'].fillna(df['Age'].mean())  # Mean\n",
        "df['Age'].fillna(df['Age'].median(), inplace=True)  # Median\n",
        "df['Age'].fillna(df['Age'].mode()[0], inplace=True)  # Mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XkyudGIBwZL",
        "outputId": "99fd6a1c-fd3d-4a0b-d65d-6cb2844be67d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Minyau$\\AppData\\Local\\Temp\\ipykernel_896\\2141200117.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Age'].fillna(method='ffill', inplace=True)  # Forward fill\n",
            "C:\\Users\\Minyau$\\AppData\\Local\\Temp\\ipykernel_896\\2141200117.py:2: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df['Age'].fillna(method='ffill', inplace=True)  # Forward fill\n",
            "C:\\Users\\Minyau$\\AppData\\Local\\Temp\\ipykernel_896\\2141200117.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Age'].fillna(method='bfill', inplace=True)  # Backward fill\n",
            "C:\\Users\\Minyau$\\AppData\\Local\\Temp\\ipykernel_896\\2141200117.py:3: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df['Age'].fillna(method='bfill', inplace=True)  # Backward fill\n"
          ]
        }
      ],
      "source": [
        "# Forward/Backward Fill\n",
        "df['Age'].fillna(method='ffill', inplace=True)  # Forward fill\n",
        "df['Age'].fillna(method='bfill', inplace=True)  # Backward fill"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCSxK2y1BwZM",
        "outputId": "17cf84e6-115f-4e8d-faff-ffec9cf5f646"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Daftar kolom dalam dataset: Index(['Name', 'Age', 'City'], dtype='object')\n",
            "\n",
            "Data setelah menghapus baris dengan missing values di kolom 'Name':\n",
            "      Name   Age         City\n",
            "0    Alice  25.0     New York\n",
            "1      Bob  30.0  Los Angeles\n",
            "2  Charlie  35.0      Chicago\n",
            "4      Eve  50.0         None\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Contoh dataframe\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', None, 'Eve'],\n",
        "    'Age': [25, 30, 35, None, 50],\n",
        "    'City': ['New York', 'Los Angeles', 'Chicago', 'Miami', None]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Cek nama kolom yang ada\n",
        "print(\"Daftar kolom dalam dataset:\", df.columns)\n",
        "\n",
        "# Pastikan kolom yang dituju ada dalam dataset\n",
        "kolom_target = 'Name'  # Ubah sesuai nama kolom yang benar\n",
        "if kolom_target in df.columns:\n",
        "    df.dropna(subset=[kolom_target], inplace=True)\n",
        "    print(\"\\nData setelah menghapus baris dengan missing values di kolom '{}':\".format(kolom_target))\n",
        "    print(df)\n",
        "else:\n",
        "    print(\"\\n‚ùå Kolom '{}' tidak ditemukan dalam dataset!\".format(kolom_target))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRDpCSMSBwZM"
      },
      "source": [
        "### B. Menghapus Duplikat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dh_XhRg0BwZN",
        "outputId": "11e180a5-d9f1-433d-c02a-2340984fa2dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "# Identifikasi duplikat\n",
        "print(df.duplicated().sum())\n",
        "\n",
        "# Menghapus duplikat\n",
        "df.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5xTjeHyBwZN"
      },
      "source": [
        "### C. Menangani Outliers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNfEwF1wBwZN",
        "outputId": "95df5c46-8d1a-439a-b311-d2279ee7582d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Outliers:\n",
            " Empty DataFrame\n",
            "Columns: [Name, Age, City]\n",
            "Index: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Minyau$\\AppData\\Local\\Temp\\ipykernel_896\\4220109551.py:38: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Age'].fillna(df['Age'].median(), inplace=True)\n",
            "C:\\Users\\Minyau$\\AppData\\Local\\Temp\\ipykernel_896\\4220109551.py:39: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Name'].fillna('Unknown', inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# Langkah 1: Membuat DataFrame\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'Alice', 'Eve', np.nan],\n",
        "    'Age': [25, 30, 35, 25, np.nan, 50],\n",
        "    'City': ['New York', 'Los Angeles', 'Chicago', 'New York', 'Miami', 'Los Angeles']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Langkah 2: Identifikasi Outliers\n",
        "# Outliers dapat diidentifikasi menggunakan berbagai metode, salah satu yang umum adalah menggunakan Z-score atau IQR (Interquartile Range).\n",
        "# Di sini, kita akan menggunakan IQR untuk mendeteksi outliers.\n",
        "# Menghitung IQR\n",
        "Q1 = df['Age'].quantile(0.25)\n",
        "Q3 = df['Age'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Menentukan batas bawah dan atas untuk outliers\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Menandai outliers\n",
        "outliers = df[(df['Age'] < lower_bound) | (df['Age'] > upper_bound)]\n",
        "print(\"Outliers:\\n\", outliers)\n",
        "\n",
        "\n",
        "# Langkah 3: Menangani Outliers\n",
        "# # Menghapus outliers\n",
        "df_no_outliers = df[(df['Age'] >= lower_bound) & (df['Age'] <= upper_bound)]\n",
        "\n",
        "# Mengganti outliers dengan nilai median\n",
        "median_age = df['Age'].median()\n",
        "df['Age'] = np.where((df['Age'] < lower_bound) | (df['Age'] > upper_bound), median_age, df['Age'])\n",
        "\n",
        "# Mengisi missing values dengan median\n",
        "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
        "df['Name'].fillna('Unknown', inplace=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Brw3rc88BwZO"
      },
      "source": [
        "### D. Mengubah Data Kategorikal ke Numerik\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-pKXpuABwZO",
        "outputId": "9f034157-a36c-42b1-8d8e-a1bddac6936e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   City_Chicago  City_Los Angeles  City_Miami  City_New York\n",
            "0         False             False       False           True\n",
            "1         False              True       False          False\n",
            "2          True             False       False          False\n",
            "3         False             False       False           True\n",
            "4         False             False        True          False\n"
          ]
        }
      ],
      "source": [
        "# Contoh: misalnya, kita memiliki dataset dengan kolom \"City\" yang berisi data kategorikal:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "data = {'City': ['New York', 'Los Angeles', 'Chicago', 'New York', 'Miami']}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# One-Hot Encoding\n",
        "df_one_hot = pd.get_dummies(df, columns=['City'])\n",
        "\n",
        "print(df_one_hot)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNTmW13-BwZO",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "### E. Menangani Data Tidak Valid\n",
        "Menangani data tidak valid adalah proses penting untuk memastikan integritas dan kualitas dataset. Data tidak valid dapat mengganggu analisis dan menghasilkan model yang tidak akurat. Berikut adalah langkah-langkah yang bisa diambil untuk menangani data tidak valid:\n",
        "\n",
        "##### Identifikasi Data Tidak Valid\n",
        "1. Pemeriksaan Kesalahan: Identifikasi kesalahan ketik atau entri yang tidak sesuai format yang diharapkan.\n",
        "2. Pemeriksaan Batas Nilai: Pastikan nilai numerik berada dalam rentang yang wajar.\n",
        "3. Pemeriksaan Konsistensi: Pastikan konsistensi antar kolom, misalnya tanggal mulai tidak boleh setelah tanggal berakhir.\n",
        "4. Deteksi Anomali: Gunakan metode statistik atau algoritma untuk mendeteksi anomali dalam data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPHHYr1gBwZO"
      },
      "source": [
        "##### Penanganan Data Tidak Valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXXaL2F2BwZO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'Alice', 'Eve', np.nan],\n",
        "    'Age': [25, 30, 35, 25, np.nan, 50],\n",
        "    'City': ['New York', 'Los Angeles', 'Chicago', 'New York', 'Miami', 'Los Angeles']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Menghapus Data Tidak Valid: Jika jumlah data tidak valid kecil dan tidak signifikan, menghapusnya bisa menjadi solusi yang cepat dan mudah.\n",
        "df = df.dropna(subset=['Age', 'Name'])  # Menghapus baris dengan nilai 'Age' atau 'Name' yang tidak valid\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvBQwaxxBwZP"
      },
      "outputs": [],
      "source": [
        "# Mengganti dengan Nilai Lain:\n",
        "\n",
        "# Mengisi dengan Rata-rata/Median: Mengisi nilai yang hilang atau tidak valid dengan rata-rata atau median.\n",
        "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
        "\n",
        "# Mengisi dengan Nilai Default: Mengisi dengan nilai default yang logis atau sesuai konteks.\n",
        "df['Name'] = df['Name'].fillna('Unknown')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCYtPmTrBwZP"
      },
      "outputs": [],
      "source": [
        "# Transformasi Data: Mengubah data tidak valid menjadi format yang sesuai.\n",
        "df['Age'] = pd.to_numeric(df['Age'], errors='coerce')  # Mengubah nilai 'Age' yang tidak valid menjadi NaN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfOS7koXBwZP"
      },
      "outputs": [],
      "source": [
        "# Pembersihan dengan Logika Bisnis: Menggunakan aturan bisnis untuk memperbaiki data. Misalnya, jika usia tidak masuk akal (misalnya lebih dari 120 tahun), maka ubah atau hapus.\n",
        "df = df[(df['Age'] >= 0) & (df['Age'] <= 120)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eA3xCk4BwZQ"
      },
      "source": [
        "##### Contoh Menangani Data Tidak Valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EoHYQiwBwZQ",
        "outputId": "8b6bed1d-f567-46df-af7b-ebefbb5328c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Awal:\n",
            "      Name    Age         City\n",
            "0    Alice   25.0     New York\n",
            "1      Bob   30.0  Los Angeles\n",
            "2  Charlie   35.0      Chicago\n",
            "3    Alice   25.0     New York\n",
            "4      Eve    NaN        Miami\n",
            "5      NaN  150.0  Los Angeles\n",
            "\n",
            "Data Setelah Menangani Nilai Tidak Valid:\n",
            "      Name    Age         City\n",
            "0    Alice   25.0     New York\n",
            "1      Bob   30.0  Los Angeles\n",
            "2  Charlie   35.0      Chicago\n",
            "3    Alice   25.0     New York\n",
            "4      Eve   30.0        Miami\n",
            "5  Unknown  150.0  Los Angeles\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'Alice', 'Eve', np.nan],\n",
        "    'Age': [25, 30, 35, 25, np.nan, 150],  # 150 dianggap sebagai nilai tidak valid\n",
        "    'City': ['New York', 'Los Angeles', 'Chicago', 'New York', 'Miami', 'Los Angeles']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Identifikasi nilai tidak valid\n",
        "print(\"Data Awal:\")\n",
        "print(df)\n",
        "\n",
        "# Mengubah nilai 'Age' yang tidak valid menjadi NaN\n",
        "df['Age'] = pd.to_numeric(df['Age'], errors='coerce')\n",
        "\n",
        "# Mengisi nilai 'Age' yang hilang atau tidak valid dengan median\n",
        "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
        "\n",
        "# Mengisi nilai 'Name' yang hilang dengan 'Unknown'\n",
        "df['Name'] = df['Name'].fillna('Unknown')\n",
        "\n",
        "print(\"\\nData Setelah Menangani Nilai Tidak Valid:\")\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2I7gkLfBwZQ"
      },
      "source": [
        "Dalam contoh ini, nilai usia yang tidak valid (150) diubah menjadi nilai median, dan nama yang hilang diisi dengan 'Unknown'. Langkah-langkah ini membantu memastikan bahwa data yang digunakan untuk analisis dan pemodelan lebih bersih dan dapat diandalkan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9ptuOciBwZQ"
      },
      "source": [
        "## 2. Data Normalization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bvjZR9sBwZQ"
      },
      "source": [
        "#### Metode Normalisasi Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmJldDizBwZR"
      },
      "source": [
        "##### Contoh Normalisasi dengan Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Viu_bWKPBwZR",
        "outputId": "c7a2dd70-7764-418e-a50b-c71d9481b198"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Asli:\n",
            "   Age  Salary\n",
            "0   25   50000\n",
            "1   30   60000\n",
            "2   35   70000\n",
            "3   40   80000\n",
            "4   45   90000\n",
            "\n",
            "Min-Max Scaled Data:\n",
            "    Age  Salary\n",
            "0  0.00    0.00\n",
            "1  0.25    0.25\n",
            "2  0.50    0.50\n",
            "3  0.75    0.75\n",
            "4  1.00    1.00\n",
            "\n",
            "Standardized Data:\n",
            "        Age    Salary\n",
            "0 -1.414214 -1.414214\n",
            "1 -0.707107 -0.707107\n",
            "2  0.000000  0.000000\n",
            "3  0.707107  0.707107\n",
            "4  1.414214  1.414214\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# Contoh dataset\n",
        "data = {\n",
        "    'Age': [25, 30, 35, 40, 45],\n",
        "    'Salary': [50000, 60000, 70000, 80000, 90000]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Min-Max Scaling\n",
        "min_max_scaler = MinMaxScaler()\n",
        "df_min_max_scaled = pd.DataFrame(min_max_scaler.fit_transform(df), columns=df.columns)\n",
        "\n",
        "# Z-Score Normalization\n",
        "standard_scaler = StandardScaler()\n",
        "df_standard_scaled = pd.DataFrame(standard_scaler.fit_transform(df), columns=df.columns)\n",
        "\n",
        "print(\"Data Asli:\")\n",
        "print(df)\n",
        "\n",
        "print(\"\\nMin-Max Scaled Data:\")\n",
        "print(df_min_max_scaled)\n",
        "\n",
        "print(\"\\nStandardized Data:\")\n",
        "print(df_standard_scaled)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNqPnh0FBwZS"
      },
      "source": [
        "Dalam contoh ini, kita melihat bagaimana fitur Age dan Salary diubah menggunakan Min-Max Scaling dan Z-Score Normalization. Setelah normalisasi, data berada dalam rentang yang lebih seragam, yang membantu meningkatkan kinerja model machine learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9qDeRwQBwZS"
      },
      "source": [
        "## 3. Validasi Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99WfkeLnBwZS"
      },
      "source": [
        "#### Teknik Validasi Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81IdMDJpBwZT"
      },
      "source": [
        "##### Contoh Implementasi K-Fold Cross-Validation di Python\n",
        "Berikut adalah contoh bagaimana mengimplementasikan K-Fold Cross-Validation menggunakan scikit-learn di Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cHo2dfrBwZT",
        "outputId": "0f900998-c88d-4db4-fa37-b86f7154fa81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Fold Cross-Validation Scores: [nan nan nan nan nan]\n",
            "Mean Score: nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Minyau$\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "c:\\Users\\Minyau$\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "c:\\Users\\Minyau$\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "c:\\Users\\Minyau$\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n",
            "c:\\Users\\Minyau$\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Contoh dataset\n",
        "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]])\n",
        "y = np.array([2, 3, 4, 5, 6])\n",
        "\n",
        "# Model\n",
        "model = LinearRegression()\n",
        "\n",
        "# K-Fold Cross-Validation\n",
        "kf = KFold(n_splits=5)\n",
        "scores = cross_val_score(model, X, y, cv=kf)\n",
        "\n",
        "print(\"K-Fold Cross-Validation Scores:\", scores)\n",
        "print(\"Mean Score:\", np.mean(scores))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHN_yZ_FBwZT"
      },
      "source": [
        "Outputnya adalah skor kinerja model untuk setiap fold dan rata-rata skornya, yang memberikan gambaran umum tentang kinerja model Validasi model adalah langkah kritis dalam machine learning yang membantu memastikan bahwa model yang dikembangkan adalah akurat, andal, dan mampu menangani data yang tidak terlihat dengan baik. Dengan menggunakan teknik validasi yang tepat, kita dapat memilih model terbaik dan mengoptimalkan kinerjanya untuk aplikasi dunia nyata."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgiv_4ZNBwZT"
      },
      "source": [
        "## 4. K-Fold Cross-Validation\n",
        "K-Fold Cross-Validation adalah salah satu teknik validasi model yang umum digunakan dalam machine learning untuk mengevaluasi kinerja model secara lebih akurat. Teknik ini membagi dataset menjadi k subset (folds) yang sama besar, di mana setiap fold digunakan sebagai set pengujian satu kali sementara k-1 folds lainnya digunakan sebagai set pelatihan. Berikut ini adalah langkah-langkah dan manfaat utama dari K-Fold Cross-Validation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hINEkzqvBwZT"
      },
      "source": [
        "##### Langkah-langkah K-Fold Cross-Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rogy5qgsBwZU",
        "outputId": "e3c325e9-aadc-4678-b1fb-70c6a51e83a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Fold Cross-Validation Scores: [1.         1.         0.93333333 0.96666667 0.96666667]\n",
            "Mean Score: 0.9733333333333334\n"
          ]
        }
      ],
      "source": [
        "# Implementasi K-Fold Cross-Validation di Python\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# K-Fold Cross-Validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)  # Misalnya, menggunakan 5 folds dengan shuffle dan seed random 42\n",
        "scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n",
        "\n",
        "print(\"K-Fold Cross-Validation Scores:\", scores)\n",
        "print(\"Mean Score:\", scores.mean())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ny8E8fJ2BwZU"
      },
      "source": [
        "Dalam contoh di atas, dataset Iris dibagi menjadi 5 folds dengan shuffle dan seed random yang ditentukan. Model Regresi Logistik dievaluasi menggunakan metrik akurasi, dan hasil dari setiap fold dievaluasi dan dihitung rata-ratanya. K-Fold Cross-Validation adalah alat yang penting dalam evaluasi model machine learning untuk memastikan bahwa model yang dikembangkan dapat diandalkan dan dapat digeneralisasikan dengan baik pada data yang tidak terlihat sebelumnya."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuydhDpYBwZU"
      },
      "source": [
        "## 5. Confussion Matrix\n",
        "Confusion Matrix (matriks kebingungan) adalah tabel yang digunakan untuk mengevaluasi kinerja suatu model klasifikasi pada sebuah dataset yang sudah diketahui labelnya. Matriks ini menggambarkan jumlah hasil prediksi yang benar dan yang salah dalam empat kategori berbeda."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrAx2tppBwZU"
      },
      "source": [
        "#### Interpretasi Confusion Matrix\n",
        "Matriks kebingungan memberikan gambaran yang lebih komprehensif tentang kinerja model klasifikasi daripada metrik evaluasi tunggal seperti akurasi. Dengan menggunakan komponen-komponen tersebut, beberapa metrik evaluasi lain dapat dihitung, seperti:\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD3sIYBABwZU"
      },
      "source": [
        "##### Contoh Confusion Matrix\n",
        "\n",
        "Misalkan kita memiliki sebuah confusion matrix sebagai berikut:\n",
        "\n",
        "```lua\n",
        "\n",
        "            Predicted\n",
        "         |  0   |  1  |\n",
        "Actual   |------|-----|\n",
        "   0     |  50  |  10 |\n",
        "   1     |  5   |  35 |\n",
        "\n",
        "\n",
        "Dari matriks ini:\n",
        "\n",
        "    True Positive (TP) = 50\n",
        "    True Negative (TN) = 35\n",
        "    False Positive (FP) = 10\n",
        "    False Negative (FN) = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sa0gubOrBwZU"
      },
      "source": [
        "Dengan informasi ini, kita bisa menghitung akurasi, presisi, recall, dan F1-score untuk mengevaluasi performa model klasifikasi tersebut. Confusion matrix adalah alat yang sangat berguna untuk memahami seberapa baik model klasifikasi kita bekerja pada dataset tertentu, terutama dalam konteks klasifikasi yang tidak seimbang atau ketika perlu menilai dampak dari kesalahan prediksi tertentu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOgJrWvYBwZV"
      },
      "source": [
        "## 6. Bootstrap Sampling\n",
        "Bootstrap sampling adalah teknik resampling yang digunakan dalam statistik untuk mengevaluasi keandalan estimasi dari sebuah sampel data. Teknik ini memungkinkan kita untuk membuat estimasi dari sebaran (distribution) suatu statistik, seperti mean, median, atau deviasi standar, bahkan jika distribusi dari populasi tidak diketahui.\n",
        "\n",
        "\n",
        "\n",
        "##### Contoh Bootstrap Sampling\n",
        "Misalkan kita memiliki dataset berikut yang berisi nilai-nilai tinggi dari suatu populasi:\n",
        "\n",
        "Data: [10, 15, 8, 12, 14, 20, 18, 16, 11, 13]\n",
        "\n",
        "Bootstrap sampling adalah teknik resampling yang digunakan dalam statistik untuk mengevaluasi keandalan estimasi dari sebuah sampel data. Teknik ini memungkinkan kita untuk membuat estimasi dari sebaran (distribution) suatu statistik, seperti mean, median, atau deviasi standar, bahkan jika distribusi dari populasi tidak diketahui.\n",
        "\n",
        "##### Konsep Dasar Bootstrap Sampling\n",
        "1. Resampling: Bootstrap sampling melibatkan pengambilan sampel dari dataset yang ada dengan mengembalikan (dengan penggantian) observasi yang sudah diambil. Ini berarti setiap observasi dalam dataset asli memiliki kesempatan untuk muncul di dalam sampel bootstrap lebih dari satu kali atau bahkan tidak muncul sama sekali.\n",
        "2. Estimasi Sebaran: Dengan membuat banyak sampel bootstrap (biasanya ribuan sampai jutaan), kita dapat membangun distribusi dari statistik yang ingin diestimasi. Misalnya, kita dapat menghitung mean dari setiap sampel bootstrap, dan distribusi dari mean tersebut akan memberi kita perkiraan tentang sebaran mean dari populasi.\n",
        "3. Keuntungan: Bootstrap sampling mengatasi masalah ketidakpastian tentang distribusi dari populasi, karena kita tidak harus bergantung pada asumsi tertentu tentang distribusi. Teknik ini juga memberikan interval kepercayaan (confidence intervals) yang lebih akurat.\n",
        "\n",
        "##### Langkah-langkah Implementasi Bootstrap Sampling\n",
        "1. Ambil Sampel: Ambil sampel dari dataset asli sebanyak n kali, dengan penggantian.\n",
        "2. Hitung Statistik: Hitung statistik dari setiap sampel bootstrap, seperti mean, median, deviasi standar, atau persentil.\n",
        "3. Bangun Distribusi: Dengan menggunakan hasil statistik dari banyak sampel bootstrap, bangun distribusi dari statistik tersebut.\n",
        "4. Interval Kepercayaan: Dengan distribusi yang telah dibangun, hitung interval kepercayaan untuk estimasi statistik tertentu, misalnya 95% confidence interval.\n",
        "\n",
        "##### Contoh Bootstrap Sampling\n",
        "\n",
        "Misalkan kita memiliki dataset berikut yang berisi nilai-nilai tinggi dari suatu populasi:\n",
        "\n",
        "Data: [10, 15, 8, 12, 14, 20, 18, 16, 11, 13]\n",
        "\n",
        "Kita ingin mengevaluasi rata-rata (mean) dari populasi ini menggunakan bootstrap sampling:\n",
        "1. Ambil Sampel: Ambil n sampel dengan penggantian dari dataset asli. Misalnya, kita ambil 1000 sampel bootstrap.\n",
        "2. Hitung Mean: Hitung mean dari setiap sampel bootstrap.\n",
        "3. Bangun Distribusi: Dengan menggunakan mean dari sampel bootstrap, kita dapat membangun distribusi mean dari populasi.\n",
        "4. Interval Kepercayaan: Hitung 95% confidence interval dari distribusi mean yang dibangun."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZD-4AOTBwZV"
      },
      "source": [
        "Berikut adalah contoh implementasi sederhana menggunakan Python untuk menghitung mean dan confidence interval dengan bootstrap sampling:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHhC9e6vBwZV",
        "outputId": "ebd245f4-fcc4-487c-ce4b-64855a8d5636"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean: 13.7\n",
            "95% Confidence Interval: 11.5 - 15.9\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Data\n",
        "data = np.array([10, 15, 8, 12, 14, 20, 18, 16, 11, 13])\n",
        "\n",
        "# Bootstrap sampling\n",
        "n_samples = 1000\n",
        "bootstrap_means = np.zeros(n_samples)\n",
        "\n",
        "for i in range(n_samples):\n",
        "    bootstrap_sample = np.random.choice(data, size=len(data), replace=True)\n",
        "    bootstrap_means[i] = np.mean(bootstrap_sample)\n",
        "\n",
        "# Confidence interval (95%)\n",
        "ci_lower = np.percentile(bootstrap_means, 2.5)\n",
        "ci_upper = np.percentile(bootstrap_means, 97.5)\n",
        "\n",
        "print(\"Mean:\", np.mean(data))\n",
        "print(\"95% Confidence Interval:\", ci_lower, \"-\", ci_upper)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZuxUVWcBwZW"
      },
      "source": [
        "Dalam contoh ini, kita mengambil 1000 sampel bootstrap dari data, menghitung mean dari setiap sampel, dan kemudian menghitung 95% confidence interval dari distribusi mean yang dibangun. Bootstrap sampling adalah alat yang powerful untuk memperoleh estimasi yang stabil dan distribusi statistik dari data yang ada.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8EI2nJkBwZW"
      },
      "source": [
        "## 7. Evaluasi Kinerja Model\n",
        "Evaluasi kinerja model adalah proses penting dalam machine learning untuk menilai seberapa baik model dapat melakukan prediksi terhadap data yang belum pernah dilihat sebelumnya. Tujuannya adalah untuk memastikan bahwa model dapat digeneralisasikan dengan baik dan bekerja dengan akurat pada situasi dunia nyata. Berikut ini adalah langkah-langkah umum dalam evaluasi kinerja model:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eR44-hGeBwZW"
      },
      "source": [
        "##### Contoh Implementasi Evaluasi Kinerja Model di Python\n",
        "Berikut adalah contoh sederhana menggunakan Python untuk evaluasi kinerja model klasifikasi menggunakan metrik akurasi dan confusion matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mk1DE1AdBwZW",
        "outputId": "49f10542-0734-47e8-d6d2-fd2424c94ca7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 1.0\n",
            "Confusion Matrix:\n",
            " [[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Bagi dataset menjadi data pelatihan dan data pengujian\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Inisialisasi dan latih model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Prediksi dengan data pengujian\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluasi kinerja model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19q95LD1BwZX",
        "outputId": "5e01bd99-c26a-4378-87e8-f30bd5a04c4c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package movie_reviews to\n",
            "[nltk_data]     C:\\Users\\Minyau$\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[168  31]\n",
            " [ 36 165]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.82      0.84      0.83       199\n",
            "         pos       0.84      0.82      0.83       201\n",
            "\n",
            "    accuracy                           0.83       400\n",
            "   macro avg       0.83      0.83      0.83       400\n",
            "weighted avg       0.83      0.83      0.83       400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Contoh Confussion Matrix di NLP\n",
        "# Impor library yang diperlukan\n",
        "import nltk\n",
        "from nltk.corpus import movie_reviews\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Unduh dataset sentimen ulasan film dari NLTK\n",
        "nltk.download('movie_reviews')\n",
        "\n",
        "# Ambil ulasan dan label dari dataset\n",
        "documents = [(list(movie_reviews.words(fileid)), category)\n",
        "             for category in movie_reviews.categories()\n",
        "             for fileid in movie_reviews.fileids(category)]\n",
        "\n",
        "# Pisahkan teks ulasan dan label\n",
        "texts = [' '.join(document) for document, category in documents]\n",
        "labels = [category for document, category in documents]\n",
        "\n",
        "# Ubah teks menjadi vektor fitur TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X = vectorizer.fit_transform(texts)\n",
        "\n",
        "# Bagi dataset menjadi data pelatihan dan data pengujian\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Inisialisasi dan latih model klasifikasi (misalnya, Linear SVM)\n",
        "classifier = LinearSVC()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Prediksi kelas pada data pengujian\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Evaluasi model menggunakan confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Evaluasi model menggunakan classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}